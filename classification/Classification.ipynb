{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Supervised Learning - Text Classification</center>\n",
    "References:\n",
    "* http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What we'll cover in this lecture\n",
    "* Review basic concepts of machine learning\n",
    "  * Cross validation\n",
    "  * Performance metrics: recall and precision\n",
    "* Text Classification  \n",
    "  * Assign a document into one  or more pre-defined categories (or labels)\n",
    "    * Input: \n",
    "      - a document $d$ \n",
    "      - a fixed set of classes C = {$c_1$, $c_2$,..., $c_J$}\n",
    "      - A training set of $m$ hand-labeled documents ($d_1,c_1$),....,($d_m,c_m$)\n",
    "    * Output: a classifier that predicts $d$ to some classes $c$ $\\subset$ C\n",
    "  * **Single-label** classification: e.g. spam dection\n",
    "  * **Multi-label** classification: e.g. news categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review basic concepts of machine learning\n",
    "### 2.1. Cross validation \n",
    "  * Defition: model valiation technique for assessing how a model will generalize to an independent data set\n",
    "  * *k*-fold cross validation: \n",
    "    - Often, there is not enough data to allow some of it to be kept back for testing. \n",
    "    - Thus, the data is separated into k subsets. Each time, one of the subsets is held as the test set (a.k.a holdout) and the rest of them is used as the training set. \n",
    "    - This method repeats *k* times and each time with a different subset as the test set. \n",
    "  <img src=\"cross_validation.png\" width=\"50%\"> [source] (http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Performance metrics\n",
    "  * Precision: precentage of true cases among the predicated true cases\n",
    "  * Recall:  precentage of true cases that have been retrieved over the total number of true cases\n",
    "  * F-score: $$\\frac{2*precision*recall}{precision+recall}$$\n",
    "  * Example: \n",
    "Confusion Matrix: <img src=\"confusion_matrix.png\">\n",
    "    * For \"YES\" group: \n",
    "      - precision=100/(100+10)=0.91, \n",
    "      - recall=100/(100+5)=0.95, \n",
    "      - f-score=2\\*0.91\\*0.95/(0.91+0.95)=0.92\n",
    "      <img src=\"precision_recall.png\" width=\"60%\">\n",
    "    * For \"NO\" group:\n",
    "      - precision=?, \n",
    "      - recall=?, \n",
    "      - f-score=?\n",
    "  * Overall model performance\n",
    "    * precision_macro (or recall_macro or f1_macro) is calculated as:\n",
    "      1. calculate precision for each label\n",
    "      2. average over labels \n",
    "    * pericision_micro (or recall_micro or f1_micro): calculates metrics globally regardless of labels\n",
    "    * With inbalanced classes, the difference between these two metrics may be significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Basic process\n",
    "  1. Load and preprocess training data\n",
    "  2. Extract features: e.g. bag of words with TF-IDF weights\n",
    "  3. Split data into trainning and test sets following cross validation method\n",
    "  4. Train a classifier/model with the training dataset using selected classification algorithm for each fold\n",
    "  5. Calculate performance\n",
    " \n",
    "* Considerations for deciding text classification algorithms\n",
    "  - should be effective in high dimensional spaces\n",
    "  - should be effective even if the number of features is greater than the number of samples\n",
    "    * Is regression a good alogorithm if you have a small number of text samples?\n",
    "  - some good algorithms to start with:\n",
    "      - Naive Bayes (https://web.stanford.edu/class/cs124/lec/naivebayes.pdf): baseline for performance benchmarking of text classification algorithms\n",
    "      - Support Vector Machine (SVM) (https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "Group: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.: Load data \n",
    "# Load datasets (http://qwone.com/~jason/20Newsgroups/)\n",
    "# For convenience, a subset of the data has been saved into \"twenty_news_data.pkl\"\n",
    "\n",
    "import pickle\n",
    "data=pickle.load(open(\"twenty_news_data.pkl\",\"r\"))\n",
    "\n",
    "# data is a list of tuple (text, label)\n",
    "# print out the first document\n",
    "print(\"Text: \"+data[0][0]+\"\\nGroup: \"+data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.2. Prepare text and class labels\n",
    "\n",
    "# split data as list of tuples into text and target tuples\n",
    "text,target=zip(*data)\n",
    "\n",
    "# convert tuple to list\n",
    "text=list(text)\n",
    "target=list(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. TF-IDF matrix generation\n",
    "- Function: **sklearn.feature_extraction.text.TfidfVectorizer**(input='content',encoding='utf-8', decode_error='strict', token_pattern='(?u)\\b\\w\\w+\\b', lowercase=True, stop_words=None, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, smooth_idf=True, ...)\n",
    "- Some useful parameters:\n",
    "    * **input** : string {'filename', 'file', 'content').\n",
    "    * **encoding** : string, 'utf-8' by default.\n",
    "If bytes or files are given to analyze, this encoding is used to decode.\n",
    "    * **decode_error** : {'strict', 'ignore', 'replace'}: Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given encoding. By default, it is 'strict', meaning that a UnicodeDecodeError will be raised. Other values are ‘ignore’ and ‘replace’.\n",
    "    * **token_pattern** : Regular expression denoting what constitutes a “token”. The default is '(?u)\\b\\w\\w+\\b', i.e. a token contains at least two word characters in unicode (note: ?u: unicode, \\b: space or non-word character, i.e. boundary, \\w: word character). \n",
    "    * **ngram_range** : tuple (min_n, max_n): The lower and upper boundary of the range of n-values for different n-grams to be extracted. \n",
    "    * **stop_words** : string {‘english’}, list, or None (default)\n",
    "    * **lowercase** : boolean, default True: Convert all characters to lowercase before tokenizing.\n",
    "    * **max_df/min_df** : float in range [0.0, 1.0] or int, default=1.0: When building the vocabulary ignore terms that have a document frequency strictly higher (lower) than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "    * **max_features** : int or None, default=None. If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "    * **norm** : 'l1', 'l2' or None, optional. Norm used to normalize term vectors. None for no normalization.\n",
    "    * **use_idf** : boolean, default=True. Enable inverse-document-frequency reweighting.\n",
    "    * **smooth_idf** : boolean, default=True. Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.\n",
    "- For all the parameters, see http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1b3dd3b7759c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;31m# generate tfidf matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdtm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"type of dtm:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3. Create TF-IDF Matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the TfidfVectorizer \n",
    "\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "# with stop words removed\n",
    "#tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "# generate tfidf matrix\n",
    "dtm= tfidf_vect.fit_transform(text)\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for scripy sparse matrix, use data to read non zero values in the matrix; use indices to read corresponding index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01679781,  0.13487106,  0.31440007,  0.12491818,  0.11819702,\n",
       "        0.19622799,  0.38418039,  0.01679781,  0.21567206,  0.0744441 ,\n",
       "        0.07283774,  0.17358472,  0.24645541,  0.18626015,  0.03637492,\n",
       "        0.03429071,  0.03604415,  0.11382739,  0.01776232,  0.08865416,\n",
       "        0.06567578,  0.01686489,  0.05966162,  0.03779319,  0.043162  ,\n",
       "        0.03478259,  0.01824994,  0.04270369,  0.04334165,  0.06866113,\n",
       "        0.07802072,  0.08413454,  0.0979625 ,  0.099941  ,  0.07830787,\n",
       "        0.12806013,  0.1232277 ,  0.10218403,  0.13635772,  0.04525255,\n",
       "        0.07691883,  0.03448147,  0.03127031,  0.03900412,  0.03590436,\n",
       "        0.03104295,  0.04727158,  0.1232277 ,  0.11947938,  0.04935883,\n",
       "        0.1256015 ,  0.03109515,  0.06899051,  0.01996488,  0.02387114,\n",
       "        0.06350566,  0.05417404,  0.04910237,  0.01894546,  0.06866113,\n",
       "        0.08497461,  0.04967185,  0.09313008,  0.08631915,  0.25612026,\n",
       "        0.24645541,  0.10783603,  0.13487106,  0.10960586,  0.06666452,\n",
       "        0.13487106,  0.13487106,  0.13487106])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('type of vocabulary:', <type 'dict'>)\n",
      "(\"index of word 'city' in vocabulary:\", 8696)\n",
      "('total number of words:', 35788)\n",
      "\n",
      "Original text: \n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "\n",
      "tfidf weights: \n",
      "\n",
      "[(u'collier', 0.3841803935867984), (u'city', 0.31440006552897398), (u'071', 0.25612026239119895), (u'477', 0.24645540709354397), (u'laserjet', 0.24645540709354397), (u'converting', 0.21567205914741705), (u'michael', 0.1962279892331408), (u'iii', 0.18626015109199115), (u'hp', 0.17358472047671197), (u'files', 0.13635772403701527), (u'0hb', 0.1348710554299733), (u'8565', 0.1348710554299733), (u'ec1v', 0.1348710554299733), (u'sd345', 0.1348710554299733), (u'x3769', 0.1348710554299733), (u'tif', 0.12806013119559947), (u'email', 0.12560149999130399), (u'ac', 0.12491817585060791), (u'hpgl', 0.12322770354677198), (u'img', 0.12322770354677198), (u'plotter', 0.11947938145690981), (u'uk', 0.11819702490105698), (u'hampton', 0.11382738609462074), (u'london', 0.10960585507802437), (u'8000', 0.10783602957370853), (u'tga', 0.10218403421141944), (u'utility', 0.099940999780369397), (u'pd', 0.097962503194823067), (u'unit', 0.093130075545995575), (u'the', 0.088654162537216877), (u'tel', 0.086319151311621767), (u'programmer', 0.084974609434708512), (u'application', 0.084134544090855731), (u'convert', 0.078307873261798555), (u'pc', 0.078020724286186352), (u'format', 0.076918833859470528), (u'images', 0.074444101878853294), (u'to', 0.072837739416165184), (u'response', 0.068990508106723969), (u'advance', 0.068661128807969402), (u'standard', 0.068661128807969402), (u'fax', 0.066664521378597255), (u'university', 0.065675780431863881), (u'correct', 0.063505656471953387), (u'14', 0.059661620128702707), (u'group', 0.054174041798686907), (u'computer', 0.049671845493333165), (u'please', 0.049358833839754077), (u'thanks', 0.049102373804466713), (u'same', 0.047271576160535234), (u'into', 0.045252554088454071), (u'way', 0.043341654399042764), (u'anyone', 0.043161997007118758), (u'good', 0.042703686357211466), (u'also', 0.039004124261009951), (u'does', 0.037793189755988436), (u'nntp', 0.036374916362300114), (u'host', 0.036044147187848298), (u'like', 0.035904358813682244), (u'know', 0.034782593244413566), (u'we', 0.034481472140846715), (u'posting', 0.034290706362898604), (u'would', 0.031270309783357403), (u'any', 0.031095148592215401), (u'do', 0.031042954435189937), (u'this', 0.023871142738151236), (u'is', 0.019964881751854364), (u'in', 0.018945464349599841), (u'of', 0.018249940796073682), (u'organization', 0.017762318563562172), (u'lines', 0.016864892977128034), (u'from', 0.016797806021219684), (u'subject', 0.016797806021219684)]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.4. Examine TF-IDF\n",
    "\n",
    "# 1. Check vocabulary\n",
    "# Vocabulary is a dictionary mapping a word to an index\n",
    "print(\"type of vocabulary:\", type(tfidf_vect.vocabulary_))\n",
    "print(\"index of word 'city' in vocabulary:\", tfidf_vect.vocabulary_['city'])\n",
    "\n",
    "# the number of words in the vocabulary\n",
    "print(\"total number of words:\", len(tfidf_vect.vocabulary_ ))\n",
    "\n",
    "# 2. check the weight of words in a document, e.g. 1st document\n",
    "\n",
    "# first, covert the sparse matrix row to a list\n",
    "doc0=dtm[0].toarray()[0]\n",
    "\n",
    "print(\"\\nOriginal text: \\n\"+text[0])\n",
    "print(\"\\ntfidf weights: \\n\")\n",
    "\n",
    "# second, get mapping from word index to word\n",
    "# i.e. reversal mapping of tfidf_vect.vocabulary_\n",
    "voc_lookup={tfidf_vect.vocabulary_[word]:word \\\n",
    "            for word in tfidf_vect.vocabulary_}\n",
    "\n",
    "# get words with tfidf weight>0\n",
    "tfidf_words=[(voc_lookup[i], doc0[i]) for i in range(len(doc0)) if doc0[i]>0]\n",
    "print(sorted(tfidf_words, key=lambda item:-item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multinomial Naive bayes;\n",
    "for a text datasets, D documents, V vocabulary including x_i, i in {0, ... n} words, for each d, word x from V.\n",
    "C classes of topics.\n",
    "P(c_j) = count of c_j / total count of documents\n",
    "P(x_i | c_j) = count of x_i in c_j / total words in c_j\n",
    "P(x_i) = count of x_i in all documents / total words\n",
    "\n",
    "P(c_j | x_d_k) approx. => P(x_d_k | c_j) * P(c_j), where x_d_k is set of words in d_k\n",
    "Using naive Bayes rule, assuming each word is independent of each other.\n",
    "P(x_d_k | c_j) = P(x_0_d_k | c_j) * P(x_1_d_k | c_j) * ... * P(x_m_d_k | c_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sci.med', 'soc.religion.christian', 'alt.atheism', 'comp.graphics']\n",
      "[ 0.91758242  0.95675676  0.97222222  0.96407186]\n",
      "[ 0.97093023  0.94148936  0.95890411  0.93604651]\n",
      "[ 0.94350282  0.94906166  0.96551724  0.94985251]\n",
      "[172 188 146 172]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               sci.med       0.97      0.96      0.97       146\n",
      "soc.religion.christian       0.96      0.94      0.95       172\n",
      "           alt.atheism       0.92      0.97      0.94       172\n",
      "         comp.graphics       0.96      0.94      0.95       188\n",
      "\n",
      "           avg / total       0.95      0.95      0.95       678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.5. classification using a single fold\n",
    "\n",
    "# use MultinomialNB algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import method for split train/test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import method to calculate metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import metrics\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, target, test_size=0.3, random_state=0)\n",
    "\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB(alpha = 0).fit(X_train, y_train)\n",
    "\n",
    "# predict the news group for the test dataset\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "# get the list of unique labels\n",
    "labels=list(set(target))\n",
    "\n",
    "# calculate performance metrics. \n",
    "# Support is the number of occurrences of each label\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(y_test, predicted, labels=labels)\n",
    "\n",
    "print(labels)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(fscore)\n",
    "print(support)\n",
    "\n",
    "# another way to get all performance metrics\n",
    "print(metrics.classification_report(y_test, predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When alpha = 0, performace improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 35788)\n",
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.6.  predict new documents\n",
    "\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "\n",
    "# generate tifid for new documents\n",
    "X_new_tfidf = tfidf_vect.transform(docs_new)\n",
    "\n",
    "print(X_new_tfidf.shape)\n",
    "\n",
    "# predict classes for new documents\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for idx, doc in enumerate(docs_new):\n",
    "    print('%r => %s' % (doc, predicted[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.7. Classification with stop words removed\n",
    "# Can removing stop words improves performance?\n",
    "# In Exercise 3.3, uncomment line 10 and comment line 7\n",
    "# Run Exercise 3.3\n",
    "# Run Exercise 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[ 0.97733303  0.97465317  0.96643912  0.97238159  0.97849985]\n",
      "\n",
      "Test data set average recall:\n",
      "[ 0.97435482  0.97221897  0.96284397  0.97017065  0.9774104 ]\n",
      "\n",
      "Test data set average fscore:\n",
      "[ 0.97561608  0.97320334  0.96424212  0.97114142  0.97781257]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.8. Run 5 fold cross validation\n",
    "# to show the generalizability of the model\n",
    "\n",
    "# import cross validation method\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "#clf = MultinomialNB()\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "\n",
    "cv = cross_validate(clf, dtm, target, scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n",
    "\n",
    "# To see the performance of training data set use cv['train_xx_macro']\n",
    "\n",
    "# The metrics are quite stable across folds.\n",
    "# The performance between training and test sets is small\n",
    "# This indicates the model has good generality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([ 0.04247713,  0.01781797,  0.01361394,  0.01305008,  0.01426411]),\n",
       " 'score_time': array([ 0.01673484,  0.011163  ,  0.006778  ,  0.00617504,  0.00602102]),\n",
       " 'test_f1_macro': array([ 0.97561608,  0.97320334,  0.96424212,  0.97114142,  0.97781257]),\n",
       " 'test_precision_macro': array([ 0.97733303,  0.97465317,  0.96643912,  0.97238159,  0.97849985]),\n",
       " 'test_recall_macro': array([ 0.97435482,  0.97221897,  0.96284397,  0.97017065,  0.9774104 ]),\n",
       " 'train_f1_macro': array([ 0.99777202,  0.99778033,  0.99946919,  0.99777202,  0.99777532]),\n",
       " 'train_precision_macro': array([ 0.9979098 ,  0.99792961,  0.99946581,  0.9979098 ,  0.99791416]),\n",
       " 'train_recall_macro': array([ 0.99764529,  0.99764529,  0.99947368,  0.99764529,  0.9976475 ])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.9. Multinominal NB with different smoothing parameter alpha\n",
    "# comment line 11 and uncomment 12 in Exercise 3.8\n",
    "# use different alpha value to see if it affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[ 0.97019783  0.97449526  0.96449132  0.96739007  0.97877082]\n",
      "\n",
      "Test data set average recall:\n",
      "[ 0.9680339   0.97376396  0.96232313  0.96444238  0.97789593]\n",
      "\n",
      "Test data set average fscore:\n",
      "[ 0.96898048  0.97398282  0.96303024  0.9652361   0.978057  ]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.10. SVM model\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "# initiate an linear SVM model\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "cv = cross_validate(clf, dtm, target, scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Parameter tuning using grid search\n",
    "* Each classification model has a few parameters\n",
    "  * e.g. \"stop_words\": \"english\" or None, min_df: [1,2,3, ...]\n",
    "  * e.g. MultinomialNB(alpha=1.0)\n",
    "  * e.g. LinearSVC(penalty=’l2’, loss=’squared_hinge’,...)\n",
    "* Instead of tweaking the parameters of the various components, it is possible to run an exhaustive search of the best parameters on a grid of possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a9b86645226c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[1;31m# it may take long time to search for optimal parameter combination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[1;31m# you can use a subset of data to test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mgs_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[0;32m--> 471\u001b[0;31m                                   is_multimetric)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[1;32m    501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\metrics\\scorer.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     99\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[1;32m    100\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\utils\\metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mE:\\ProgramData\\anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Exercise 3.3.1 Grid search\n",
    "\n",
    "# import pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# build a pipeline which does two steps all together:\n",
    "# (1) generate tfidf, and (2) train classifier\n",
    "# each step is named, i.e. \"tfidf\", \"clf\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                   ])\n",
    "\n",
    "# set the range of parameters to be tuned\n",
    "# each parameter is defined as \n",
    "# <step name>__<parameter name in step>\n",
    "# e.g. mid_df is a parameter of TfidfVectorizer()\n",
    "# \"tfidf\" is the name for TfidfVectorizer()\n",
    "# therefore, 'tfidf__min_df' is the parameter in grid search\n",
    "\n",
    "parameters = {'tfidf__min_df':[2,3],\n",
    "              'tfidf__stop_words':[None,\"english\"],\n",
    "              'clf__alpha': [0.5,1.0,2.0],\n",
    "}\n",
    "\n",
    "# the metric used to select the best parameters\n",
    "metric =  \"f1_macro\"\n",
    "\n",
    "# GridSearch also uses cross validation\n",
    "gs_clf = GridSearchCV(text_clf, param_grid=parameters, scoring=metric, cv=5)\n",
    "\n",
    "# due to data volume and large parameter combinations\n",
    "# it may take long time to search for optimal parameter combination\n",
    "# you can use a subset of data to test\n",
    "gs_clf = gs_clf.fit(text, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tfidf__stop_words', ': ', 'english')\n",
      "('tfidf__min_df', ': ', 2)\n",
      "('clf__alpha', ': ', 0.5)\n",
      "('best f1 score:', 0.96846636442327894)\n"
     ]
    }
   ],
   "source": [
    "# gs_clf.best_params_ returns a dictionary \n",
    "# with parameter and its best value as an entry\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(param_name,\": \",gs_clf.best_params_[param_name])\n",
    "\n",
    "print(\"best f1 score:\", gs_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3.3.2 Grid search\n",
    "# Modify Exercise 3.3 and Exercise 3.8 \n",
    "# to use the best parameters found\n",
    "# re-create the Multinominal NB classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-label classification\n",
    "- So far we only cover single-label classification, i.e. assign one class to each sample\n",
    "- Multilabel classification emerges as a challenging problem, where classes are not mutually exclusive \n",
    "  * music categorization \n",
    "  * semantic classification of images\n",
    "  * tagging\n",
    "- **One-Vs-the-Rest** Strategy (a.k.a **one-vs-all**)\n",
    "  * fitting one classifier per class. For each classifier, the class is fitted against all the other classes.\n",
    "  * for $n$ classes (labels), $n$ classifier is needed\n",
    "  * Advantage: good interpretability - Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier\n",
    "  * Disadvantage: \n",
    "     * many classifiers are created if there is a large number classes\n",
    "     * ignore the structure (or dependencies) of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [0 1]\n",
      " [1 1]]\n",
      "nice day in nyc => New York\n",
      "welcome to london => London\n",
      "hello welcome to new york. enjoy it here and london too => New York, London\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4.1 Multi-label classification\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# import OneVsRestClassifier, a wrap for all individual classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "X_train = np.array([\"new york is a hell of a town\",\n",
    "                    \"new york was originally dutch\",\n",
    "                    \"the big apple is great\",\n",
    "                    \"new york is also called the big apple\",\n",
    "                    \"nyc is nice\",\n",
    "                    \"people abbreviate new york city as nyc\",\n",
    "                    \"the capital of great britain is london\",\n",
    "                    \"london is in the uk\",\n",
    "                    \"london is in england\",\n",
    "                    \"london is in great britain\",\n",
    "                    \"it rains a lot in london\",\n",
    "                    \"london hosts the british museum\",\n",
    "                    \"new york is great and so is london\",\n",
    "                    \"i like london better than new york\"])\n",
    "\n",
    "target_names = ['New York', 'London']\n",
    "\n",
    "# The target needs to be an indicator matrix y_train\n",
    "# where y_train[i,j] means the jth label of sample i\n",
    "# e.g. y_train[0,0]=[1,0] means the first sample is \n",
    "# labeled with 'New York' but not 'London'\n",
    "\n",
    "y_train = np.array([[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],\\\n",
    "           [0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[1,1],[1,1]])\n",
    "X_test = np.array(['nice day in nyc',\n",
    "                   'welcome to london',\n",
    "                   'hello welcome to new york. enjoy it here and london too'])   \n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print(predicted)\n",
    "\n",
    "for idx, p in enumerate(predicted):\n",
    "    predicted_labels=[target_names[x] for x in [0,1] if p[x]==1]\n",
    "    print('%s => %s' % (X_test[idx], ', '.join(predicted_labels) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
